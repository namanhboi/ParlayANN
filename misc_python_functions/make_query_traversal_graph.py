import ast
import pandas as pd
import matplotlib.pyplot as plt
import argparse
from textwrap import wrap
import math
import random
import sigmoid_fit
import numpy as np
from scipy.signal import argrelextrema


def parse_input_file(path: str):
    """
    parses file generated by record_query_traversal_path.cpp and returns
    data for graph
    """
    # with open(path, "r") as f:
    #     # command = f.readline()
    #     # query_index = int(f.readline())
    #     lines = [line.rstrip().split(",") for line in f]

    # x_axis, y_axis = list(zip(*lines))
    # x_axis_values = [int(i) for i in x_axis]
    # y_axis_values = [math.log(int(i) + 1) for i in y_axis]
    # # y_axis_values = [int(i) for i in y_axis]
    # return x_axis_values, y_axis_values
    df = pd.read_csv(path)
    df.traversal_path = df.traversal_path.apply(lambda x : ast.literal_eval(x))
    return df

def parse_traversal_path(traversal_path: list):
    visited_indices, visited_rank, visited_timestamp = map(list, zip(*traversal_path))
    visited_rank = list(map(lambda x: math.log(x + 1), visited_rank))
    return visited_indices, visited_rank, visited_timestamp

def segmented_least_squares(x, y, num_segments):
    """
    Perform segmented least squares regression by dividing the data into
    segments and fitting a line to each segment.
    
    Parameters:
    -----------
    x : array-like
        Independent variable data (must be sorted in ascending order).
    y : array-like
        Dependent variable data.
    num_segments : int
        Number of line segments to fit.
    
    Returns:
    --------
    segment_points : list
        The x-coordinates of the breakpoints between segments.
    segment_models : list
        List of tuples (slope, intercept) for each segment.
    total_error : float
        Sum of squared errors for the segmented fit.
    """
    x = np.array(x)
    y = np.array(y)
    
    # Ensure x is sorted in ascending order
    if not np.all(np.diff(x) >= 0):
        raise ValueError("x array must be sorted in ascending order")
    
    if num_segments < 1:
        raise ValueError("Number of segments must be at least 1")
    
    if num_segments == 1:
        # For one segment, perform simple linear regression
        slope, intercept = np.polyfit(x, y, 1)
        y_pred = slope * x + intercept
        error = np.sum((y - y_pred)**2)
        return [], [(slope, intercept)], error
    
    # Function to calculate the total squared error for a given set of breakpoints
    def calculate_error(breakpoints):
        # Add start and end points
        all_points = np.concatenate(([x[0]], breakpoints, [x[-1]]))
        total_error = 0
        segment_models = []
        
        # Fit each segment
        for i in range(len(all_points) - 1):
            # Get indices for this segment
            start_idx = np.searchsorted(x, all_points[i], side='left')
            end_idx = np.searchsorted(x, all_points[i+1], side='right')
            
            # Check if segment has enough points
            if end_idx - start_idx < 2:
                return float('inf')  # Invalid segmentation
            
            # Fit line to this segment
            segment_x = x[start_idx:end_idx]
            segment_y = y[start_idx:end_idx]
            slope, intercept = np.polyfit(segment_x, segment_y, 1)
            segment_models.append((slope, intercept))
            
            # Calculate error for this segment
            y_pred = slope * segment_x + intercept
            segment_error = np.sum((segment_y - y_pred)**2)
            total_error += segment_error
        
        return total_error, segment_models
    
    # Try different combinations of breakpoints using dynamic programming approach
    best_error = float('inf')
    best_breakpoints = []
    best_models = []
    
    # Initialize the DP table: opt[i][j] = min cost to fit j segments in x[0:i]
    n = len(x)
    opt = np.full((n, num_segments + 1), float('inf'))
    bp = np.zeros((n, num_segments + 1), dtype=int)  # To store breakpoints
    
    # Cost for fitting one segment to data from i to j
    def segment_cost(i, j):
        if j - i < 2:  # Need at least 2 points for a line
            return float('inf'), (0, 0)  # Return dummy model with infinite cost
        slope, intercept = np.polyfit(x[i:j], y[i:j], 1)
        y_pred = slope * x[i:j] + intercept
        return np.sum((y[i:j] - y_pred)**2), (slope, intercept)
    
    # Base case: cost for fitting one segment
    for i in range(n):
        cost, model = segment_cost(0, i+1)
        opt[i][1] = cost
    
    # Fill DP table
    for j in range(2, num_segments + 1):  # Number of segments
        for i in range(n):  # End position
            for k in range(j-1, i):  # Try all positions for the last breakpoint
                cost, model = segment_cost(k, i+1)
                if opt[k-1][j-1] + cost < opt[i][j]:
                    opt[i][j] = opt[k-1][j-1] + cost
                    bp[i][j] = k
    
    # Reconstruct solution by backtracking
    breakpoints = []
    pos = n - 1
    
    for j in range(num_segments, 0, -1):
        if j > 1:  # No breakpoint needed for the first segment
            breakpoints.append(x[bp[pos][j]])
        pos = bp[pos][j] - 1
    
    breakpoints.reverse()
    
    # Calculate the final segmentation
    final_error, final_models = calculate_error(np.array(breakpoints))
    
    return breakpoints, final_models, final_error
def plot_segmented_least_squares(x, y, num_segments, color, alpha,num_points=1000):
    """
    Plot the results of segmented least squares regression.
    
    Parameters:
    -----------
    x : array-like
        Independent variable data (must be sorted in ascending order).
    y : array-like
        Dependent variable data.
    num_segments : int
        Number of line segments to fit.
    num_points : int, optional (default=1000)
        Number of points to use when plotting the fitted lines.
    
    Returns:
    --------
    breakpoints : list
        The x-coordinates of the breakpoints between segments.
    segment_models : list
        List of tuples (slope, intercept) for each segment.
    total_error : float
        Sum of squared errors for the segmented fit.
    """
    x = np.array(x)
    y = np.array(y)
    
    # Perform segmented least squares using the main function
    breakpoints, segment_models, total_error = segmented_least_squares(x, y, num_segments)
    
    # Prepare for plotting
    # plt.scatter(x, y, color='blue', alpha=0.5, label='Data Points')
    
    # Add start and end points to breakpoints
    all_points = np.concatenate(([x[0]], breakpoints, [x[-1]]))
    
    # Generate and plot fitted lines for each segment
    for i in range(len(segment_models)):
        slope, intercept = segment_models[i]
        start_x = all_points[i]
        end_x = all_points[i+1]
        
        # Create more points for smooth line
        segment_x = np.linspace(start_x, end_x, num_points // num_segments)
        segment_y = slope * segment_x + intercept
        
        # Plot segment
        plt.plot(segment_x, segment_y, '-', linewidth=2, color = color, alpha = alpha)
        # plt.scatter(segment_x, segment_y[-1], 'o')
        
        # Display equation
        mid_x = (start_x + end_x) / 2
        mid_y = slope * mid_x + intercept
        equation = f"y = {slope:.2f}x + {intercept:.2f}"
        # plt.text(mid_x, mid_y, equation, fontsize=9, 
                 # bbox=dict(facecolor='white', alpha=0.7))
    
    # Mark breakpoints
    # print(breakpoints)
    # if breakpoints:
    #     for bp in breakpoints:
    #         plt.axvline(x=bp, color=color, linestyle='--', alpha=0.2)
            # plt.text(bp, np.min(y), f"x={bp:.2f}", rotation=90, 
                     # verticalalignment='bottom', fontsize=9)
    
    # plt.title(f'Segmented Least Squares with {num_segments} segments\nTotal Error: {total_error:.4f}')
    # plt.xlabel('x')
    # plt.ylabel('y')
    # plt.grid(True, alpha=0.3)
    # plt.legend()
    
    return breakpoints, segment_models, total_error




def make_vbase_graph(output_path, df, num_lines):
    """
    create the vbase graph and saves it in the current directory with name : [title].png
    title: should contain information about graph, query node, query params
    """
    # current_index = 0
    # x_y_data = []
    # for i in range(99):
    #     for j in range(current_index + 1, current_index + 100):
    #         if x_axis[j] == 0:
    #             x_y_data.append((x_axis[current_index:j], y_axis[current_index:j]))
                
    #             current_index = j
    #             break
    random_data_idx = random.sample(range(0, len(df.index)), num_lines)
    alpha = 0.2
    L_arr = []
    x0_arr = []
    k_arr = []
    b_arr = []
    num_dont_fit = 0
    line_drawn = False
    for i in random_data_idx:
        if not line_drawn:
            alpha = 0.5
            line_drawn = True
        else:
            alpha = 0.2

        visited_indices, visited_rank, visited_timestamp = parse_traversal_path(df.traversal_path.iloc[i])
        
        pl = plt.plot(np.arange(len(visited_indices)), visited_rank, "x-", alpha=alpha)
            # popt, pcov = sigmoid_fit.fit_sigmoid(np.arange(len(visited_indices)), visited_rank)
            # x = np.linspace(0, 20, 1000)
        plot_segmented_least_squares(np.arange(len(visited_indices)), visited_rank, num_segments = 2, color = pl[0].get_color(), alpha = alpha)
            # y = sigmoid_fit.sigmoid(x, *popt)
            # y_d1 = np.gradient(y, x)
            # y_d2 = np.gradient(y_d1, x)
            # y_d3 = np.gradient(y_d2, x)
            # y_d4 = np.gradient(y_d3, x)
            # argc = argrelextrema(y_d3, np.less)
            # infls = np.where(np.diff(np.sign(y_d4)))[0]
            # p , e = optimize.curve_fit(piecewise_linear,np.arange(len(visited_indices)), visited_rank, p0=[x.mean(), y.mean(),0,0])

            # plt.plot(x, piecewise_linear(x, *p), alpha = 0.2, color =pl[0].get_color())



    # popt, pcov = sigmoid_fit.fit_sigmoid(x_axis, y_axis)
    # x = np.linspace(0, 30, 500)
    # y = sigmoid_fit.sigmoid(x, *popt)
    # y_d1 = np.gradient(y, x)
    # y_d2 = np.gradient(np.gradient(y, x), x)
    # argc = argrelextrema(y_d2, np.greater)

    # infls = np.where(np.diff(np.sign(y_d2)))[0]
    # # plt.scatter(x[infls], y[infls], color="red", label="Inflection Points", zorder=3)
    # plt.scatter(x[argc], y[argc], color="red", zorder=3, label = 'local maxima of 2nd derivative')
    # # plt.plot(x, y, label = 'fit')
    
    plt.xlim([0, 30])
    plt.suptitle("\n".join(wrap("# hops from origin vs log of distance rank", 60)))
    plt.xlabel("Number of hops along path from origin to query")
    plt.ylabel("Log of rank of distance from origin of node")
    # plt.text(15, 5, f"L:{popt[0]}\nx0: {popt[1]}\nk:{popt[2]}\nb: {popt[3]}")
    plt.tight_layout()
    plt.savefig(output_path)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-p", "--path", help="path to the input file generated by vbase_graph.cpp"
    )
    parser.add_argument(
        "-nl", "--num-line", help="number of lines"
    )
    args = parser.parse_args()
    path = args.path
    df = (parse_input_file(path))
    print(df.describe())
    print(parse_traversal_path(df.traversal_path.iloc[0]))
    make_vbase_graph("vbase.png", df, int(args.num_line))
    
    
    # x_axis, y_axis = parse_input_file(path)
    # make_vbase_graph(x_axis, y_axis)
